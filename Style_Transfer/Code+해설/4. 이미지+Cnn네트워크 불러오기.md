# **신경망 스타일 전이 (Neural Style Transfer) 코드 해설**

이 문서는 스타일 전이 학습의 초기 단계인 **데이터 로드, 모델 설정 및 데이터 정규화 과정**에 대해 상세히 설명합니다.

## **1\. 실습을 위한 이미지 불러오기**

스타일 전이 알고리즘을 수행하기 위해서는 기본적으로 두 장의 이미지가 필요합니다.

* **콘텐츠 이미지 (Content Image):** 전체적인 형태와 구조를 유지할 이미지 (예: 건물 사진)  
* **스타일 이미지 (Style Image):** 색감, 질감, 붓터치 등을 가져올 이미지 (예: 빈센트 반 고흐의 그림)

### **\[코드 예시\]**

\# 이미지 로더를 사용하여 두 이미지를 (512, 640\) 크기로 리사이징하여 불러옵니다.  
content\_img \= image\_loader('./code\_practices/images/content\_img\_1.jpg', (512, 640))  
style\_img \= image\_loader('./code\_practices/images/style\_img\_1.jpg', (512, 640))

\# 불러온 이미지를 화면에 출력하여 확인합니다.  
print("\[ Content Image \]")  
imshow(content\_img)

print("\[ Style Image \]")  
imshow(style\_img)

**해설:** image\_loader는 파일 경로를 입력받아 이미지를 **텐서(Tensor)** 형태로 변환하고, 지정된 해상도로 크기를 조절합니다. 네트워크의 연산 효율과 메모리 제한을 고려하여 두 이미지의 크기를 동일하게 맞추는 것이 일반적입니다.

## **2\. CNN 네트워크(VGG19) 불러오기**

이미지의 특징(Feature)을 효과적으로 추출하기 위해 이미지 인식 분야에서 성능이 검증된 **VGG19** 모델을 사용합니다.

### **\[코드 예시\]**

\# 사전 학습된 (pretrained) VGG19 모델의 특징 추출 부분(.features)만 불러옵니다.  
cnn \= models.vgg19(pretrained=True).features.to(device).eval()  
print(cnn)

* **pretrained=True**: ImageNet 데이터셋으로 이미 학습이 완료된 가중치(Weights)를 가져옵니다. 이를 통해 모델은 선, 면, 질감 등 이미지의 고유한 특성을 즉시 이해할 수 있습니다.  
* **features**: VGG19는 특징 추출(Conv layers)과 분류(Linear layers) 부분으로 나뉩니다. 스타일 전이에서는 사물 분류 정보가 아닌 이미지 자체의 '특징'이 필요하므로 **분류층을 제외한 특징 추출층**만 사용합니다.  
* **.to(device)**: 모델을 GPU(CUDA) 또는 CPU로 이동시켜 연산을 수행할 장치를 지정합니다.  
* **.eval()**: 모델을 **평가 모드**로 전환합니다. 스타일 전이 과정에서는 모델의 가중치를 업데이트하지 않고 이미지만 변형하므로, Dropout이나 Batch Normalization 등이 학습 모드로 작동하지 않게 고정합니다.

## **3\. 입력 데이터 정규화(Normalization)**

딥러닝 모델은 입력 데이터의 분포가 일정할 때 학습 효율이 극대화됩니다. VGG 모델은 ImageNet 데이터셋의 평균과 표준편차를 기준으로 학습되었으므로, 입력 이미지도 동일한 기준으로 정규화해야 합니다.

### **정규화 계수 설정**

cnn\_normalization\_mean \= torch.tensor(\[0.485, 0.456, 0.406\]).to(device)  
cnn\_normalization\_std \= torch.tensor(\[0.229, 0.224, 0.225\]).to(device)

이 수치들은 ImageNet 데이터셋 전체의 R, G, B 채널별 평균($\\mu$)과 표준편차($\\sigma$)입니다.

### **정규화 클래스 정의**

class Normalization(nn.Module):  
    def \_\_init\_\_(self, mean, std):  
        super(Normalization, self).\_\_init\_\_()  
        \# 계산을 위해 \[C, 1, 1\] 형태로 차원을 변경(view)하여 저장합니다.  
        self.mean \= mean.clone().view(-1, 1, 1\)  
        self.std \= std.clone().view(-1, 1, 1\)

    def forward(self, img):  
        \# 정규화 공식: (이미지 \- 평균) / 표준편차  
        return (img \- self.mean) / self.std

**요약:**

1. **\_\_init\_\_**: 평균과 표준편차 값을 받아 이미지 텐서와 연산이 가능한 형태로 모양을 바꿉니다. view(-1, 1, 1)은 채널 수(3)를 유지하면서 너비와 높이 방향으로 \*\*브로드캐스팅(Broadcasting)\*\*될 수 있게 합니다.  
2. forward: 실제 이미지가 들어왔을 때 수행되는 연산입니다. 수식으로는 다음과 같습니다.  
   $$x\_{norm} \= \\frac{x \- \\mu}{\\sigma}$$

## **결론**

이 코드는 VGG19라는 거대한 신경망의 눈을 빌려와서, 우리가 넣은 건물 사진(Content)과 고흐의 그림(Style)을 분석할 준비를 마치는 과정입니다. 특히 **Normalization** 과정을 통해 모델이 원래 학습했던 데이터와 유사한 환경을 만들어 줌으로써 더 정확한 특징 추출이 가능하게 합니다.