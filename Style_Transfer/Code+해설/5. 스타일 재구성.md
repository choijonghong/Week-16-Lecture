# **Style Reconstruction(스타일 재구성) 상세 해설**

이 문서는 특정 이미지의 \*\*'스타일'\*\*을 수학적인 값으로 계산하고, 아무것도 없는 '노이즈(noise)' 상태의 이미지를 그 스타일과 닮아지도록 조금씩 깎고 다듬는 과정을 설명합니다.

## **1\. Gram Matrix (그램 행렬): 스타일의 "지문" 만들기**

gram\_matrix 함수는 이미지의 스타일을 수치화하는 핵심 도구입니다.

def gram\_matrix(input):  
    a, b, c, d \= input.size()  \# 배치 크기, 채널 수, 가로, 세로  
    features \= input.view(a \* b, c \* d)  \# 데이터를 계산하기 편하게 펴줍니다.  
    G \= torch.mm(features, features.t())  \# 행렬 곱셈을 통해 상관관계를 구합니 다.  
    return G.div(a \* b \* c \* d)  \# 크기로 나누어 정규화합니다.

* **쉬운 설명:** 이미지에서 어떤 색깔이나 무늬가 함께 자주 나타나는지 통계를 내는 것입니다.  
* **예시:** "고흐의 그림에서 파란색과 소용돌이 무늬가 자주 같이 나타난다"라는 특징을 숫자로 뽑아내는 과정입니다. 위치는 상관없이 전체적인 분위기(지문)만 추출합니다.

## **2\. StyleLoss (스타일 손실): "얼마나 닮았니?" 측정기**

스타일이 목표와 얼마나 다른지 계산하는 클래스입니다.

class StyleLoss(nn.Module):  
    def \_\_init\_\_(self, target\_feature):  
        super(StyleLoss, self).\_\_init\_\_()  
        \# 목표 스타일 이미지의 '지문(Gram Matrix)'을 미리 저장해둡니다.  
        self.target \= gram\_matrix(target\_feature).detach()

    def forward(self, input):  
        \# 현재 변하고 있는 이미지의 '지문'을 계산합니다.  
        G \= gram\_matrix(input)  
        \# 두 지문의 차이(MSE)를 구합니다.  
        self.loss \= F.mse\_loss(G, self.target)  
        return input

* **쉬운 설명:** "내가 만들고 싶은 스타일"과 "지금 내 이미지의 스타일"을 비교해서 점수를 매깁니다. 차이가 클수록 loss 점수가 높게 나옵니다.

## **3\. get\_style\_losses: 모델에 "스타일 감시관" 배치하기**

기존의 CNN(VGG 모델 등) 사이에 우리가 만든 StyleLoss 레이어를 끼워 넣는 과정입니다.

* **동작 방식:**  
  1. 인공지능 모델의 레이어를 하나씩 훑어봅니다.  
  2. 레이어의 이름을 붙여줍니다 (conv\_1, relu\_1 등).  
  3. 설정한 style\_layers 리스트에 있는 레이어를 만나면, 그 지점에 StyleLoss라는 감시관을 배치합니다.  
  4. 마지막 감시관 이후의 쓸모없는 레이어들은 다 잘라냅니다.

## **4\. style\_reconstruction: 실제 스타일 입히기 (최적화)**

가장 중요한 실행 단계입니다. 하얀 노이즈를 예술 작품의 스타일로 변하게 만듭니다.

def style\_reconstruction(cnn, style\_img, input\_img, iters):  
    \# 모델을 준비하고 스타일 감시관들을 가져옵니다.  
    model, style\_losses \= get\_style\_losses(cnn, style\_img, input\_img)  
      
    \# 이미지의 픽셀값들을 직접 수정하는 최적화 도구(LBFGS)를 설정합니다.  
    optimizer \= optim.LBFGS(\[input\_img.requires\_grad\_()\])

    \# ... 반복 학습 시작 ...  
    def closure():  
        optimizer.zero\_grad() \# 이전 점수는 지우고  
        model(input\_img)      \# 이미지를 모델에 통과시켜 스타일 점수를 계산합니다.  
          
        style\_score \= 0  
        for sl in style\_losses:  
            style\_score \+= sl.loss \# 모든 레이어의 스타일 점수를 합칩니다.  
              
        style\_score \*= 1e6 \# 점수를 크게 만들어 학습이 잘 되게 합니다.  
        style\_score.backward() \# "이미지를 어떻게 바꿔야 할지" 계산  
        return style\_score

* **쉬운 설명:**  
  1. **준비:** 아무렇게나 생긴 노이즈 이미지(치직거리는 화면 같은 것)를 준비합니다.  
  2. **비교:** 이 노이즈를 모델에 넣고 "스타일 감시관"들에게 점수를 받습니다.  
  3. **수정:** 감시관이 "이 부분은 좀 더 소용돌이 모양이어야 해"라고 알려주면, 그 방향으로 이미지의 픽셀 색깔을 살짝 바꿉니다.  
  4. **반복:** 이 과정을 수백 번(iters) 반복하면 노이즈가 어느새 스타일을 닮게 됩니다.

## **5\. 실행 및 요약**

\# 1\. 노이즈 이미지 만들기  
input\_img \= torch.empty\_like(content\_img).uniform\_(0, 1).to(device)

\# 2\. 스타일 재구성 시작\! (300번 동안 다듬기)  
output \= style\_reconstruction(cnn, style\_img=style\_img, input\_img=input\_img, iters=300)

### **핵심 요약**

1. 스타일은 이미지 전체의 통계적인 특징(**Gram Matrix**)입니다.  
2. 이 특징을 노이즈 이미지에 강제로 주입하기 위해, 딥러닝 모델로 점수를 매기며 **픽셀 하나하나를 수정**하는 과정입니다.  
3. 결과물은 원본 이미지의 형체는 없지만, 질감과 색감은 타겟 이미지를 쏙 빼닮은 독특한 패턴 이미지가 됩니다.